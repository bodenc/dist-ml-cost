Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/rcv1_small.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.000000   1.000000            1         1.0   1.0000   0.0000       50
1.159804   1.319608            2         2.0  -1.0000   0.1487      103
1.036629   0.913455            4         4.0  -1.0000  -0.0996      134
0.913158   0.789687            8         8.0  -1.0000  -0.3868      145
0.853525   0.793891           16        16.0   1.0000   0.0040       23
0.857877   0.862230           32        32.0  -1.0000  -0.1942       31
0.866947   0.876017           64        64.0  -1.0000  -0.6024       60
0.845120   0.823293          128       128.0   1.0000   0.4470      105
0.689798   0.534476          256       256.0   1.0000   0.3825      122
0.586888   0.483978          512       512.0  -1.0000   0.1124       74
0.492310   0.397732         1024      1024.0  -1.0000  -0.4830      155
0.416231   0.340152         2048      2048.0   1.0000  -0.7794       61
0.373915   0.331598         4096      4096.0  -1.0000   0.9608      114
0.337363   0.300812         8192      8192.0  -1.0000  -0.2149      307

finished run
number of examples per pass = 10000
passes used = 1
weighted example sum = 10000
weighted label sum = -636
average loss = 0.325263
best constant = -0.0636
total feature number = 2425076
