Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
using no cache
Reading datafile = train-sets/rcv1_small.dat
num sources = 1
average    since         example     example  current  current  current
loss       last          counter      weight    label  predict features
1.000000   1.000000            1         1.0   1.0000   0.0000       50
1.159804   1.319608            2         2.0  -1.0000   0.1487      103
1.036629   0.913455            4         4.0  -1.0000  -0.0996      134
0.913158   0.789687            8         8.0  -1.0000  -0.3868      145
0.853525   0.793891           16        16.0   1.0000   0.0040       23
0.857877   0.862230           32        32.0  -1.0000  -0.1942       31
0.866947   0.876017           64        64.0  -1.0000  -0.6024       60
0.845120   0.823293          128       128.0   1.0000   0.4470      105
0.689798   0.534476          256       256.0   1.0000   0.3825      122
0.586888   0.483978          512       512.0  -1.0000   0.1124       74
0.492272   0.397656         1024      1024.0  -1.0000  -0.4748       99
0.398941   0.305610         2048      2048.0   1.0000   0.4012       61
0.357933   0.316926         4096      4096.0  -1.0000  -0.5026      114
0.328979   0.300025         8192      8192.0  -1.0000  -0.3542      409

finished run
number of examples per pass = 10000
passes used = 1
weighted example sum = 10000
weighted label sum = -636
average loss = 0.316975
best constant = -0.0636
total feature number = 1939722
