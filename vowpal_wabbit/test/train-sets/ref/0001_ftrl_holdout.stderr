using l1 regularization = 0.9
final_regressor = models/0001_ftrl.model
Enabling FTRL based optimization
Algorithm used: Proximal-FTRL
ftrl_alpha = 3
ftrl_beta = 0
Num weight bits = 18
learning rate = 0.5
initial_t = 0
power_t = 0.5
decay_learning_rate = 1
creating cache_file = train-sets/0001.dat.cache
Reading datafile = train-sets/0001.dat
num sources = 1
average  since         example        example  current  current  current
loss     last          counter         weight    label  predict features
1.000000 1.000000            1            1.0   1.0000   0.0000       51
1.000000 1.000000            2            2.0   0.0000   1.0000      104
0.500000 0.000000            4            4.0   0.0000   0.0000      135
0.500000 0.500000            8            8.0   0.0000   0.0000      146
0.312500 0.125000           16           16.0   1.0000   1.0000      143
0.403125 0.493750           32           32.0   1.0000   0.0022       70
0.391543 0.379961           64           64.0   0.0000   0.0185       34
0.376947 0.362352          128          128.0   0.0000   0.4202       30
0.258484 0.140021          256          256.0   0.0000   0.2416       72
0.154604 0.050723          512          512.0   0.0000   0.0000       37
0.080430 0.006255         1024         1024.0   1.0000   0.8557       94

finished run
number of examples = 1260
weighted example sum = 1260.000000
weighted label sum = 560.000000
average loss = 0.094317 h
best constant = 0.444444
best constant's loss = 0.246914
total feature number = 96481
